{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078e046a",
   "metadata": {},
   "source": [
    "\n",
    "# üß™ Treino Comparativo (4‚Äì5 Modelos) ‚Äî **Match Candidato √ó Vaga***\n",
    "\n",
    "Notebook ajustado para:\n",
    "- Ler **`data/processed/decision_consolidated.parquet`**;\n",
    "- Harmonizar colunas com/sem prefixo (ex.: `prospect_status` ‚áÑ `prospect__prospect_status`);\n",
    "- Criar **labels** de *match* de forma resiliente;\n",
    "- Fazer **split robusto** (estratificado e por grupos quando poss√≠vel, com *fallbacks*);\n",
    "- Treinar **4‚Äì5 modelos** e salvar o **melhor** (`models/recommender.pkl` + `models/recommender_meta.json`).\n",
    "\n",
    "> Use este notebook quando o merge/prefixos alterarem nomes de colunas e o split anterior quebrar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a19383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE          : C:\\Users\\dphat\\OneDrive\\Documentos\\Cursos\\FIAP\\PosTech_DataAnalytics\\fase5\\Datathon Decision\n",
      "PARQUET_PATH  : C:\\Users\\dphat\\OneDrive\\Documentos\\Cursos\\FIAP\\PosTech_DataAnalytics\\fase5\\Datathon Decision\\data\\processed\\decision_consolidated.parquet\n",
      "MODELS_DIR    : C:\\Users\\dphat\\OneDrive\\Documentos\\Cursos\\FIAP\\PosTech_DataAnalytics\\fase5\\Datathon Decision\\models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ajuste o caminho base se necess√°rio (Windows)\n",
    "BASE = Path(r\"C:\\Users\\dphat\\OneDrive\\Documentos\\Cursos\\FIAP\\PosTech_DataAnalytics\\fase5\\Datathon Decision\")\n",
    "DATA_PROCESSED = BASE / \"data\" / \"processed\"\n",
    "MODELS_DIR = BASE / \"models\"\n",
    "PARQUET_PATH = DATA_PROCESSED / \"decision_consolidated.parquet\"\n",
    "\n",
    "# Permitir imports do pacote local src/\n",
    "if str(BASE) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE))\n",
    "\n",
    "# Garante pastas (n√£o apaga nada)\n",
    "for p in [DATA_PROCESSED, MODELS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"BASE          :\", BASE)\n",
    "print(\"PARQUET_PATH  :\", PARQUET_PATH)\n",
    "print(\"MODELS_DIR    :\", MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42185a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape bruto: (53759, 114)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>prospect__prospect_name</th>\n",
       "      <th>prospect__prospect_status</th>\n",
       "      <th>prospect__prospect_status_norm</th>\n",
       "      <th>prospect__candidatura_dt</th>\n",
       "      <th>prospect__atualizacao_dt</th>\n",
       "      <th>prospect__prospect_comment</th>\n",
       "      <th>prospect__prospect_comment_len</th>\n",
       "      <th>...</th>\n",
       "      <th>app__id_ibrati</th>\n",
       "      <th>app__email_corporativo</th>\n",
       "      <th>app__cargo_atual</th>\n",
       "      <th>app__projeto_atual</th>\n",
       "      <th>app__cliente</th>\n",
       "      <th>app__unidade</th>\n",
       "      <th>app__data_admissao</th>\n",
       "      <th>app__data_ultima_promocao</th>\n",
       "      <th>app__nome_superior_imediato</th>\n",
       "      <th>app__email_superior_imediato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4530::25632</td>\n",
       "      <td>4530</td>\n",
       "      <td>25632</td>\n",
       "      <td>Jos√© Vieira</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>encaminhado ao requisitante</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>Encaminhado para  - PJ R$ 72,00/hora</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4530::25529</td>\n",
       "      <td>4530</td>\n",
       "      <td>25529</td>\n",
       "      <td>Srta. Isabela Cavalcante</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>encaminhado ao requisitante</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>encaminhado para  - R$ 6.000,00 ‚Äì CLT Full , n...</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4531::25364</td>\n",
       "      <td>4531</td>\n",
       "      <td>25364</td>\n",
       "      <td>Sra. Yasmin Fernandes</td>\n",
       "      <td>Contratado pela Decision</td>\n",
       "      <td>contratado pela decision</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>Data de Inicio: 12/04/2021</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id job_id applicant_id   prospect__prospect_name  \\\n",
       "0  4530::25632   4530        25632               Jos√© Vieira   \n",
       "1  4530::25529   4530        25529  Srta. Isabela Cavalcante   \n",
       "2  4531::25364   4531        25364     Sra. Yasmin Fernandes   \n",
       "\n",
       "     prospect__prospect_status prospect__prospect_status_norm  \\\n",
       "0  Encaminhado ao Requisitante    encaminhado ao requisitante   \n",
       "1  Encaminhado ao Requisitante    encaminhado ao requisitante   \n",
       "2     Contratado pela Decision       contratado pela decision   \n",
       "\n",
       "  prospect__candidatura_dt prospect__atualizacao_dt  \\\n",
       "0               2021-03-25               2021-03-25   \n",
       "1               2021-03-22               2021-03-23   \n",
       "2               2021-03-17               2021-04-12   \n",
       "\n",
       "                          prospect__prospect_comment  \\\n",
       "0               Encaminhado para  - PJ R$ 72,00/hora   \n",
       "1  encaminhado para  - R$ 6.000,00 ‚Äì CLT Full , n...   \n",
       "2                         Data de Inicio: 12/04/2021   \n",
       "\n",
       "   prospect__prospect_comment_len  ... app__id_ibrati app__email_corporativo  \\\n",
       "0                              36  ...           None                   None   \n",
       "1                              67  ...           None                   None   \n",
       "2                              26  ...           None                   None   \n",
       "\n",
       "  app__cargo_atual app__projeto_atual app__cliente app__unidade  \\\n",
       "0             None               None         None         None   \n",
       "1             None               None         None         None   \n",
       "2             None               None         None         None   \n",
       "\n",
       "   app__data_admissao app__data_ultima_promocao app__nome_superior_imediato  \\\n",
       "0                 NaT                       NaT                        None   \n",
       "1                 NaT                       NaT                        None   \n",
       "2                 NaT                       NaT                        None   \n",
       "\n",
       "  app__email_superior_imediato  \n",
       "0                         None  \n",
       "1                         None  \n",
       "2                         None  \n",
       "\n",
       "[3 rows x 114 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if not PARQUET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Parquet n√£o encontrado em {PARQUET_PATH}\")\n",
    "\n",
    "df_raw = pd.read_parquet(PARQUET_PATH)\n",
    "print(\"Shape bruto:\", df_raw.shape)\n",
    "df_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17235fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>prospect__prospect_name</th>\n",
       "      <th>prospect__prospect_status</th>\n",
       "      <th>prospect__prospect_status_norm</th>\n",
       "      <th>prospect__candidatura_dt</th>\n",
       "      <th>prospect__atualizacao_dt</th>\n",
       "      <th>prospect__prospect_comment</th>\n",
       "      <th>prospect__prospect_comment_len</th>\n",
       "      <th>...</th>\n",
       "      <th>app__id_ibrati</th>\n",
       "      <th>app__email_corporativo</th>\n",
       "      <th>app__cargo_atual</th>\n",
       "      <th>app__projeto_atual</th>\n",
       "      <th>app__cliente</th>\n",
       "      <th>app__unidade</th>\n",
       "      <th>app__data_admissao</th>\n",
       "      <th>app__data_ultima_promocao</th>\n",
       "      <th>app__nome_superior_imediato</th>\n",
       "      <th>app__email_superior_imediato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4530::25632</td>\n",
       "      <td>4530</td>\n",
       "      <td>25632</td>\n",
       "      <td>Jos√© Vieira</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>encaminhado ao requisitante</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>Encaminhado para  - PJ R$ 72,00/hora</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4530::25529</td>\n",
       "      <td>4530</td>\n",
       "      <td>25529</td>\n",
       "      <td>Srta. Isabela Cavalcante</td>\n",
       "      <td>Encaminhado ao Requisitante</td>\n",
       "      <td>encaminhado ao requisitante</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>encaminhado para  - R$ 6.000,00 ‚Äì CLT Full , n...</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4531::25364</td>\n",
       "      <td>4531</td>\n",
       "      <td>25364</td>\n",
       "      <td>Sra. Yasmin Fernandes</td>\n",
       "      <td>Contratado pela Decision</td>\n",
       "      <td>contratado pela decision</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>Data de Inicio: 12/04/2021</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id job_id applicant_id   prospect__prospect_name  \\\n",
       "0  4530::25632   4530        25632               Jos√© Vieira   \n",
       "1  4530::25529   4530        25529  Srta. Isabela Cavalcante   \n",
       "2  4531::25364   4531        25364     Sra. Yasmin Fernandes   \n",
       "\n",
       "     prospect__prospect_status prospect__prospect_status_norm  \\\n",
       "0  Encaminhado ao Requisitante    encaminhado ao requisitante   \n",
       "1  Encaminhado ao Requisitante    encaminhado ao requisitante   \n",
       "2     Contratado pela Decision       contratado pela decision   \n",
       "\n",
       "  prospect__candidatura_dt prospect__atualizacao_dt  \\\n",
       "0               2021-03-25               2021-03-25   \n",
       "1               2021-03-22               2021-03-23   \n",
       "2               2021-03-17               2021-04-12   \n",
       "\n",
       "                          prospect__prospect_comment  \\\n",
       "0               Encaminhado para  - PJ R$ 72,00/hora   \n",
       "1  encaminhado para  - R$ 6.000,00 ‚Äì CLT Full , n...   \n",
       "2                         Data de Inicio: 12/04/2021   \n",
       "\n",
       "   prospect__prospect_comment_len  ... app__id_ibrati app__email_corporativo  \\\n",
       "0                              36  ...           None                   None   \n",
       "1                              67  ...           None                   None   \n",
       "2                              26  ...           None                   None   \n",
       "\n",
       "  app__cargo_atual app__projeto_atual app__cliente app__unidade  \\\n",
       "0             None               None         None         None   \n",
       "1             None               None         None         None   \n",
       "2             None               None         None         None   \n",
       "\n",
       "   app__data_admissao app__data_ultima_promocao app__nome_superior_imediato  \\\n",
       "0                 NaT                       NaT                        None   \n",
       "1                 NaT                       NaT                        None   \n",
       "2                 NaT                       NaT                        None   \n",
       "\n",
       "  app__email_superior_imediato  \n",
       "0                         None  \n",
       "1                         None  \n",
       "2                         None  \n",
       "\n",
       "[3 rows x 114 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tenta importar m√≥dulos do projeto\n",
    "try:\n",
    "    from src.preprocessing import basic_preprocessing as _basic_preprocessing\n",
    "except Exception:\n",
    "    _basic_preprocessing = None\n",
    "\n",
    "try:\n",
    "    from src.feature_engineering import make_features as _make_features\n",
    "except Exception:\n",
    "    _make_features = None\n",
    "\n",
    "try:\n",
    "    from src.labeling import label_match as _label_match, label_engagement as _label_engagement\n",
    "except Exception:\n",
    "    _label_match, _label_engagement = None, None\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np  # <- necess√°rio em ensure_labels\n",
    "\n",
    "def _norm(s):\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return \"\"\n",
    "    return \" \".join(str(s).strip().lower().split())\n",
    "\n",
    "def _pick(df: pd.DataFrame, cands):\n",
    "    for c in cands:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def ensure_preprocessing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = df.copy()\n",
    "    # 1) aplica basic_preprocessing se existir\n",
    "    if _basic_preprocessing is not None:\n",
    "        try:\n",
    "            X = _basic_preprocessing(X)\n",
    "        except Exception as e:\n",
    "            print(\"basic_preprocessing falhou, seguindo com harmoniza√ß√£o local:\", e)\n",
    "\n",
    "    # 2) harmonia de status/coment√°rio (cria com/sem prefixo)\n",
    "    stcol = _pick(X, [\"prospect__prospect_status\", \"prospect_status\"])\n",
    "    if stcol:\n",
    "        X[\"prospect__prospect_status_norm\"] = X[stcol].apply(_norm)\n",
    "        X[\"prospect_status_norm\"] = X[\"prospect__prospect_status_norm\"]\n",
    "\n",
    "    cmt = _pick(X, [\"prospect__prospect_comment\", \"prospect_comment\"])\n",
    "    if cmt:\n",
    "        X[\"prospect__prospect_comment_len\"] = X[cmt].apply(lambda v: len(v) if isinstance(v, str) else 0)\n",
    "        X[\"prospect_comment_len\"] = X[\"prospect__prospect_comment_len\"]\n",
    "\n",
    "    return X\n",
    "\n",
    "def ensure_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = df.copy()\n",
    "    if _make_features is not None:\n",
    "        try:\n",
    "            X = _make_features(X)\n",
    "            return X\n",
    "        except Exception as e:\n",
    "            print(\"make_features falhou, seguindo sem features adicionais:\", e)\n",
    "    return X  # fallback: retorna df sem altera√ß√µes se falhar\n",
    "\n",
    "def ensure_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = df.copy()\n",
    "\n",
    "    # ----- target_match -----\n",
    "    if _label_match is not None:\n",
    "        try:\n",
    "            X[\"target_match\"] = _label_match(X)\n",
    "        except Exception as e:\n",
    "            print(\"label_match (src) falhou, aplicando local:\", e)\n",
    "            patt = re.compile(r\"(contrat|admit|oferta aceita|aprovad)\", re.IGNORECASE)\n",
    "            col = _pick(X, [\"prospect__prospect_status_norm\", \"prospect_status_norm\"])\n",
    "            if col:\n",
    "                X[\"target_match\"] = X[col].fillna(\"\").apply(lambda s: int(bool(patt.search(str(s)))))\n",
    "            else:\n",
    "                X[\"target_match\"] = pd.Series([np.nan] * len(X))\n",
    "    else:\n",
    "        patt = re.compile(r\"(contrat|admit|oferta aceita|aprovad)\", re.IGNORECASE)\n",
    "        col = _pick(X, [\"prospect__prospect_status_norm\", \"prospect_status_norm\"])\n",
    "        if col:\n",
    "            X[\"target_match\"] = X[col].fillna(\"\").apply(lambda s: int(bool(patt.search(str(s)))))\n",
    "        else:\n",
    "            X[\"target_match\"] = pd.Series([np.nan] * len(X))\n",
    "\n",
    "    # ----- target_engagement -----\n",
    "    if _label_engagement is not None:\n",
    "        try:\n",
    "            X[\"target_engagement\"] = _label_engagement(X)\n",
    "        except Exception as e:\n",
    "            print(\"label_engagement (src) falhou, aplicando local:\", e)\n",
    "            col = _pick(X, [\"prospect__prospect_comment_len\", \"prospect_comment_len\"])\n",
    "            if col:\n",
    "                thr = X[col].median()\n",
    "                X[\"target_engagement\"] = (X[col] >= thr).astype(int)\n",
    "            else:\n",
    "                X[\"target_engagement\"] = pd.Series([np.nan] * len(X))\n",
    "    else:\n",
    "        col = _pick(X, [\"prospect__prospect_comment_len\", \"prospect_comment_len\"])\n",
    "        if col:\n",
    "            thr = X[col].median()\n",
    "            X[\"target_engagement\"] = (X[col] >= thr).astype(int)\n",
    "        else:\n",
    "            X[\"target_engagement\"] = pd.Series([np.nan] * len(X))\n",
    "\n",
    "    return X\n",
    "_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf6d8c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras ap√≥s dropna(target): 53759\n",
      "Distribui√ß√£o do y: {0: 44485, 1: 9274}\n",
      "Coluna de grupos: job__nome\n",
      "N grupos distintos: 79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Features candidatas (presentes ou criadas)\n",
    "NUM_COLS = [c for c in [\"prospect_comment_len\",\"prospect__prospect_comment_len\",\n",
    "                        \"feat_skill_overlap\",\"feat_senioridade\",\"feat_senioridade_gap\",\"feat_ingles_match\"]\n",
    "            if c in df.columns]\n",
    "\n",
    "CAT_COLS = [c for c in [\"job__nivel_profissional\",\"app__area\"] if c in df.columns]\n",
    "\n",
    "data = df.dropna(subset=[\"target_match\"]).copy()\n",
    "if \"pair_id\" in data.columns:\n",
    "    data = data.drop_duplicates(subset=[\"pair_id\"])\n",
    "\n",
    "y = data[\"target_match\"].astype(int) if \"target_match\" in data.columns else pd.Series([], dtype=int)\n",
    "X = data[NUM_COLS + CAT_COLS].copy() if len(data) else pd.DataFrame(columns=NUM_COLS + CAT_COLS)\n",
    "\n",
    "# Diagn√≥stico\n",
    "print(\"Amostras ap√≥s dropna(target):\", len(X))\n",
    "print(\"Distribui√ß√£o do y:\", y.value_counts(dropna=False).to_dict())\n",
    "\n",
    "# Escolha da coluna de grupo (vaga)\n",
    "def pick_group_col(df_):\n",
    "    for c in [\"job__id\",\"job__vaga\",\"job__codigo\",\"job__cod\",\"job__nome\",\"job__titulo\",\"app__area\"]:\n",
    "        if c in df_.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "group_col = pick_group_col(data)\n",
    "groups = data[group_col] if group_col is not None else None\n",
    "print(\"Coluna de grupos:\", group_col)\n",
    "if groups is not None:\n",
    "    print(\"N grupos distintos:\", pd.Series(groups).nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3df61510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedGroupKFold indispon√≠vel: '<' not supported between instances of 'NoneType' and 'NoneType'\n",
      "GroupShuffleSplit falhou: '<' not supported between instances of 'NoneType' and 'NoneType'\n",
      "Shapes -> Xtr: (43007, 6) | Xte: (10752, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def stratified_group_split(X, y, groups=None, test_size=0.2, random_state=42):\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = pd.Series(y).reset_index(drop=True)\n",
    "    groups = (pd.Series(groups).reset_index(drop=True)) if groups is not None else None\n",
    "\n",
    "    if len(X) == 0:\n",
    "        raise ValueError(\"X ficou vazio ap√≥s filtros/merge. Verifique se o target foi criado e se as features existem.\")\n",
    "    if y.nunique() < 2:\n",
    "        print(\"‚ö†Ô∏è Target tem uma √∫nica classe. Fazendo split sem estratifica√ß√£o.\")\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=None)\n",
    "\n",
    "    # tenta StratifiedGroupKFold com n_splits seguro\n",
    "    try:\n",
    "        from sklearn.model_selection import StratifiedGroupKFold\n",
    "        n_splits = max(2, int(1 / test_size))\n",
    "        if groups is not None:\n",
    "            n_splits = min(n_splits, int(pd.Series(groups).nunique()))\n",
    "        n_splits = min(n_splits, len(X))\n",
    "        if n_splits < 2:\n",
    "            raise ValueError(\"n_splits insuficiente para SGKF.\")\n",
    "        sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        idx_tr, idx_te = next(sgkf.split(X, y, groups))\n",
    "        return X.iloc[idx_tr], X.iloc[idx_te], y.iloc[idx_tr], y.iloc[idx_te]\n",
    "    except Exception as e:\n",
    "        print(\"StratifiedGroupKFold indispon√≠vel:\", e)\n",
    "\n",
    "    # fallback: GroupShuffleSplit\n",
    "    if groups is not None:\n",
    "        try:\n",
    "            from sklearn.model_selection import GroupShuffleSplit\n",
    "            gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "            idx_tr, idx_te = next(gss.split(X, y, groups))\n",
    "            return X.iloc[idx_tr], X.iloc[idx_te], y.iloc[idx_tr], y.iloc[idx_te]\n",
    "        except Exception as e:\n",
    "            print(\"GroupShuffleSplit falhou:\", e)\n",
    "\n",
    "    # √∫ltimo recurso: split estratificado simples\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "Xtr, Xte, ytr, yte = stratified_group_split(X, y, groups, test_size=0.2, random_state=42)\n",
    "print(\"Shapes -> Xtr:\", Xtr.shape, \"| Xte:\", Xte.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3c852bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost habilitado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "def make_preprocessor(num_cols, cat_cols):\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "            (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                              (\"ohe\", ohe)]), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return pre\n",
    "\n",
    "pre = make_preprocessor(NUM_COLS, CAT_COLS)\n",
    "\n",
    "candidates = {\n",
    "    \"logreg\": Pipeline([(\"pre\", pre), (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))]),\n",
    "    \"rf\"    : Pipeline([(\"pre\", pre), (\"clf\", RandomForestClassifier(n_estimators=400, class_weight=\"balanced\"))]),\n",
    "    \"gb\"    : Pipeline([(\"pre\", pre), (\"clf\", GradientBoostingClassifier())]),\n",
    "    \"hgb\"   : Pipeline([(\"pre\", pre), (\"clf\", HistGradientBoostingClassifier())]),\n",
    "}\n",
    "\n",
    "# XGBoost opcional\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    candidates[\"xgb\"] = Pipeline([(\"pre\", pre), (\"clf\", XGBClassifier(\n",
    "        n_estimators=400, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8,\n",
    "        objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\"\n",
    "    ))])\n",
    "    print(\"XGBoost habilitado.\")\n",
    "except Exception as e:\n",
    "    print(\"XGBoost indispon√≠vel:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "073de548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] O sistema n√£o pode encontrar o arquivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dphat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: ['feat_senioridade_gap']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>BestThreshold</th>\n",
       "      <th>F1@Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hgb</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.301506</td>\n",
       "      <td>0.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.309529</td>\n",
       "      <td>0.5153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.431332</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.467681</td>\n",
       "      <td>0.5057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model     AUC  F1@0.5  BestThreshold  F1@Best\n",
       "0     xgb  0.7758  0.2933       0.255327   0.5187\n",
       "1     hgb  0.7762  0.2871       0.301506   0.5184\n",
       "2      gb  0.7745  0.2542       0.309529   0.5153\n",
       "3  logreg  0.7598  0.4889       0.431332   0.5090\n",
       "4      rf  0.7601  0.5045       0.467681   0.5057"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve\n",
    "\n",
    "results = {}\n",
    "for name, pipe in candidates.items():\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    proba = pipe.predict_proba(Xte)[:,1]\n",
    "    pred05 = (proba >= 0.5).astype(int)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(yte, proba)\n",
    "    f1_scores = 2*precisions*recalls/(precisions+recalls+1e-9)\n",
    "    best_idx = int(np.argmax(f1_scores))\n",
    "    best_thr = float(thresholds[best_idx]) if best_idx < len(thresholds) else 0.5\n",
    "    pred_best = (proba >= best_thr).astype(int)\n",
    "\n",
    "    results[name] = {\n",
    "        \"model\": pipe,\n",
    "        \"AUC\": float(np.round(roc_auc_score(yte, proba), 4)),\n",
    "        \"F1@0.5\": float(np.round(f1_score(yte, pred05), 4)),\n",
    "        \"BestThreshold\": best_thr,\n",
    "        \"F1@Best\": float(np.round(f1_score(yte, pred_best), 4))\n",
    "    }\n",
    "\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame([{**{\"model\":k}, **{m:v for m,v in v.items() if m!='model'}} for k,v in results.items()])\n",
    "df_results.sort_values([\"F1@Best\",\"AUC\"], ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb4e31bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo: xgb | F1@Best: 0.5187 | AUC: 0.7758 | BestThreshold: 0.25532734394073486\n",
      "Artefatos salvos em: C:\\Users\\dphat\\OneDrive\\Documentos\\Cursos\\FIAP\\PosTech_DataAnalytics\\fase5\\Datathon Decision\\models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Seleciona melhor por (F1@Best, AUC)\n",
    "best_name = None\n",
    "best_score = (-1.0, -1.0)\n",
    "for name, res in results.items():\n",
    "    score = (res[\"F1@Best\"], res[\"AUC\"])\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_name = name\n",
    "\n",
    "best = results[best_name]\n",
    "print(\"Melhor modelo:\", best_name, \"| F1@Best:\", best[\"F1@Best\"], \"| AUC:\", best[\"AUC\"], \"| BestThreshold:\", best[\"BestThreshold\"])\n",
    "\n",
    "# Descobrir coluna de t√≠tulo da vaga (√∫til para o app)\n",
    "def pick_job_title_col(df_):\n",
    "    for c in [\"job__titulo\",\"job__nome\",\"job__descricao\",\"job__descricao_vaga\"]:\n",
    "        if c in df_.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "job_title_col = pick_job_title_col(df)\n",
    "\n",
    "# Salvar artefatos\n",
    "import joblib, json\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(best[\"model\"], MODELS_DIR / \"recommender.pkl\")\n",
    "with open(MODELS_DIR / \"recommender_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"best_threshold\": best[\"BestThreshold\"],\n",
    "        \"metrics\": {k: v for k,v in best.items() if k!=\"model\"},\n",
    "        \"num_cols\": [c for c in NUM_COLS],\n",
    "        \"cat_cols\": [c for c in CAT_COLS],\n",
    "        \"group_col\": group_col,\n",
    "        \"job_title_col\": job_title_col\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Artefatos salvos em:\", MODELS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3da90fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Resultados (ordenados):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>BestThreshold</th>\n",
       "      <th>F1@Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.255327</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hgb</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.301506</td>\n",
       "      <td>0.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gb</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.309529</td>\n",
       "      <td>0.5153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.431332</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.467681</td>\n",
       "      <td>0.5057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model     AUC  F1@0.5  BestThreshold  F1@Best\n",
       "0     xgb  0.7758  0.2933       0.255327   0.5187\n",
       "1     hgb  0.7762  0.2871       0.301506   0.5184\n",
       "2      gb  0.7745  0.2542       0.309529   0.5153\n",
       "3  logreg  0.7598  0.4889       0.431332   0.5090\n",
       "4      rf  0.7601  0.5045       0.467681   0.5057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivos em models/:\n",
      "- recommender.pkl\n",
      "- recommender_meta.json\n",
      "- tfidf_vectorizer.joblib\n",
      "- train.py\n",
      "- utils.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüìä Resultados (ordenados):\")\n",
    "display(df_results.sort_values([\"F1@Best\",\"AUC\"], ascending=False).reset_index(drop=True))\n",
    "\n",
    "print(\"\\nArquivos em models/:\")\n",
    "for p in MODELS_DIR.glob(\"*\"):\n",
    "    print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d18286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
